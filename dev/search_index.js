var documenterSearchIndex = {"docs":
[{"location":"cmaes/#CMA-ES","page":"CMA-ES","title":"CMA-ES","text":"","category":"section"},{"location":"cmaes/","page":"CMA-ES","title":"CMA-ES","text":"CMAES","category":"page"},{"location":"cmaes/#Evolutionary.CMAES","page":"CMA-ES","title":"Evolutionary.CMAES","text":"Covariance Matrix Adaptation Evolution Strategy Implementation: (μ/μ_{I,W},λ)-CMA-ES\n\nThe constructor takes following keyword arguments:\n\nμ/mu is the number of parents\nλ/lambda is the number of offspring\nc_1 is a learning rate for the rank-one update of the covariance matrix update\nc_c is a learning rate for cumulation for the rank-one update of the covariance matrix\nc_mu is a learning rate for the rank-mu update of the covariance matrix update\nc_sigma is a learning rate for the cumulation for the step-size control\nc_m is the learning rate for the mean update, c_m leq 1\nσ0/sigma0 is the initial step size σ\nweights are recombination weights, if the weights are set to 1mu then the intermediate recombination is activated.\n\n\n\n\n\n","category":"type"},{"location":"cmaes/#Description","page":"CMA-ES","title":"Description","text":"","category":"section"},{"location":"cmaes/","page":"CMA-ES","title":"CMA-ES","text":"The Covariance Matrix Adaptation Evolution Strategy (CMA-ES) is a stochastic derivative-free numerical optimization algorithm for difficult (non-convex, ill-conditioned, multi-modal, rugged, noisy) optimization problems in continuous search spaces [1].","category":"page"},{"location":"cmaes/","page":"CMA-ES","title":"CMA-ES","text":"The current CMA-ES algorithm implementation based on a simplified outline[2].","category":"page"},{"location":"cmaes/#References","page":"CMA-ES","title":"References","text":"","category":"section"},{"location":"cmaes/","page":"CMA-ES","title":"CMA-ES","text":"[1]: Hansen, N. (2016), \"The CMA Evolution Strategy: A Tutorial\", arXiv:1604.00772","category":"page"},{"location":"cmaes/","page":"CMA-ES","title":"CMA-ES","text":"[2]: http://www.scholarpedia.org/article/Evolution_strategies","category":"page"},{"location":"mutation/#Mutation","page":"Mutation","title":"Mutation","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"In genetic algorithms and evolutionary computation, mutation is a genetic operator used to maintain a diversity from one generation of a population to the next. It is analogous to biological mutation. Mutation alters one or more gene values in a chromosome from its initial state. The purpose of mutation is to introduce diversity into the sampled population.","category":"page"},{"location":"mutation/#Mutation-Interface","page":"Mutation","title":"Mutation Interface","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"All mutation operations have following call interface mutation(individual) where individual is the member of population. The mutation function returns an in-place mutated individual.","category":"page"},{"location":"mutation/#Evolutionary-Strategy","page":"Mutation","title":"Evolutionary Strategy","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"See Strategies section for detailed description of ES strategies.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"List of ES mutation operations:","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"gaussian(::AbstractVector, ::IsotropicStrategy)\ngaussian(::AbstractVector, ::AnisotropicStrategy)\ncauchy(::AbstractVector, ::IsotropicStrategy)","category":"page"},{"location":"mutation/#Evolutionary.gaussian-Tuple{AbstractVector{T} where T, IsotropicStrategy}","page":"Mutation","title":"Evolutionary.gaussian","text":"gaussian(x, s::IsotropicStrategy)\n\nPerforms Gaussian isotropic mutation of the recombinant x given the strategy s  by adding Gaussian noise as follows:\n\nx_i^prime = x_i + ssigma mathcalN_i(01)\n\n\n\n\n\n","category":"method"},{"location":"mutation/#Evolutionary.gaussian-Tuple{AbstractVector{T} where T, AnisotropicStrategy}","page":"Mutation","title":"Evolutionary.gaussian","text":"gaussian(x, s::AnisotropicStrategy)\n\nPerforms Gaussian anisotropic mutation of the recombinant x given the strategy s  by adding Gaussian noise as follows:\n\nx_i^prime = x_i + ssigma_i mathcalN_i(01)\n\n\n\n\n\n","category":"method"},{"location":"mutation/#Evolutionary.cauchy-Tuple{AbstractVector{T} where T, IsotropicStrategy}","page":"Mutation","title":"Evolutionary.cauchy","text":"cauchy(x, s::IsotropicStrategy)\n\nPerforms isotropic mutation of the recombinant x given the strategy s  by adding a noise from the Cauchy distribution as follows:\n\nx_i^prime = x_i + ssigma_i delta_i\n\nwhere delta is a Cauchy random variable with the scale parameter t = 1 [2].\n\n\n\n\n\n","category":"method"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"List of ES strategy mutation operations:","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"gaussian(::IsotropicStrategy)\ngaussian(::AnisotropicStrategy)","category":"page"},{"location":"mutation/#Evolutionary.gaussian-Tuple{IsotropicStrategy}","page":"Mutation","title":"Evolutionary.gaussian","text":"gaussian(s::IsotropicStrategy)\n\nPerforms in-place mutation of the isotropic strategy s modifying its mutated strategy parameter sigma with Gaussian noise as follows:\n\nsigma^prime = sigma exp(tau_0 mathcalN(01))\n\n\n\n\n\n","category":"method"},{"location":"mutation/#Evolutionary.gaussian-Tuple{AnisotropicStrategy}","page":"Mutation","title":"Evolutionary.gaussian","text":"gaussian(s::AnisotropicStrategy)\n\nPerforms in-place mutation of the anisotropic strategy s modifying its mutated strategy parameter sigma with Gaussian noise as follows:\n\nsigma_i^prime = sigma_i exp(tau_0 mathcalN(01) + tau_i mathcalN(01))\n\n\n\n\n\n","category":"method"},{"location":"mutation/#Genetic-Algorithm","page":"Mutation","title":"Genetic Algorithm","text":"","category":"section"},{"location":"mutation/#Binary-Mutations","page":"Mutation","title":"Binary Mutations","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"flip\nbitinversion","category":"page"},{"location":"mutation/#Evolutionary.flip","page":"Mutation","title":"Evolutionary.flip","text":"flip(recombinant)\n\nReturns an in-place mutated binary recombinant with a bit flips at random positions.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.bitinversion","page":"Mutation","title":"Evolutionary.bitinversion","text":"bitinversion(recombinant)\n\nReturns an in-place mutated binary recombinant with its bits inverted.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Real-valued-Mutations","page":"Mutation","title":"Real-valued Mutations","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"uniform(::Real)\ngaussian\nBGA\nPM\nMIPM\nPLM","category":"page"},{"location":"mutation/#Evolutionary.uniform-Tuple{Real}","page":"Mutation","title":"Evolutionary.uniform","text":"uniform(r = 1.0)\n\nReturns an in-place real valued mutation function that performs the uniform distributed mutation [1].\n\nThe mutation operator randomly chooses a number z in from the uniform distribution on the interval -rr, the mutation range. The mutated individual is given by\n\nx_i^prime = x_i + z_i\n\n\n\n\n\n","category":"method"},{"location":"mutation/#Evolutionary.gaussian","page":"Mutation","title":"Evolutionary.gaussian","text":"gaussian(x, s::IsotropicStrategy)\n\nPerforms Gaussian isotropic mutation of the recombinant x given the strategy s  by adding Gaussian noise as follows:\n\nx_i^prime = x_i + ssigma mathcalN_i(01)\n\n\n\n\n\ngaussian(x, s::AnisotropicStrategy)\n\nPerforms Gaussian anisotropic mutation of the recombinant x given the strategy s  by adding Gaussian noise as follows:\n\nx_i^prime = x_i + ssigma_i mathcalN_i(01)\n\n\n\n\n\ngaussian(s::IsotropicStrategy)\n\nPerforms in-place mutation of the isotropic strategy s modifying its mutated strategy parameter sigma with Gaussian noise as follows:\n\nsigma^prime = sigma exp(tau_0 mathcalN(01))\n\n\n\n\n\ngaussian(s::AnisotropicStrategy)\n\nPerforms in-place mutation of the anisotropic strategy s modifying its mutated strategy parameter sigma with Gaussian noise as follows:\n\nsigma_i^prime = sigma_i exp(tau_0 mathcalN(01) + tau_i mathcalN(01))\n\n\n\n\n\ngaussian(σ = 1.0)\n\nReturns an in-place real valued mutation function that performs the normal distributed mutation [1].\n\nThe mutation operator randomly chooses a number z in from the normal distribution mathcalN(0sigma) with standard deviation sigma. The mutated individual is given by\n\nx_i^prime = x_i + z_i\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.BGA","page":"Mutation","title":"Evolutionary.BGA","text":"BGA(valrange, m = 20)\n\nReturns an in-place real valued mutation function that performs the BGA mutation scheme with the mutation range valrange and the mutation probability 1/m [1].\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.PM","page":"Mutation","title":"Evolutionary.PM","text":"PM(lower, upper, p = 2)\n\nReturns an in-place real valued mutation function that performs the Power Mutation (PM) scheme within lower and upper bound, and an index of mutation p[3].\n\nNote: The implementation is a degenerate case of Mixed Integer Power Mutation (MIPM)\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.MIPM","page":"Mutation","title":"Evolutionary.MIPM","text":"MIPM(lower, upper, p_real = 10, p_int = 4)\n\nReturns an in-place real valued mutation function that performs the Mixed Integer Power Mutation (MI-PM) scheme within lower and upper bound, and an index of mutation p_real for real value and p_int for integer values[4].\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.PLM","page":"Mutation","title":"Evolutionary.PLM","text":"PLM(lower, upper, η = 2)\n\nReturns an in-place real valued mutation function that performs the Polynomial Mutation (PLM) scheme within lower and upper bounds, and a mutation distribution index η[9].\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Combinatorial-Mutations","page":"Mutation","title":"Combinatorial Mutations","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"Note: The combinatorial mutation operations are applicable to binary vectors.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"inversion\ninsertion\nswap2\nscramble\nshifting\nEvolutionary.replace","category":"page"},{"location":"mutation/#Evolutionary.inversion","page":"Mutation","title":"Evolutionary.inversion","text":"inversion(recombinant)\n\nReturns an in-place mutated individual with a random arbitrary length segment of the genome in the reverse order.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.insertion","page":"Mutation","title":"Evolutionary.insertion","text":"insertion(recombinant)\n\nReturns an in-place mutated individual with an arbitrary element of the genome moved in a random position.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.swap2","page":"Mutation","title":"Evolutionary.swap2","text":"swap2(recombinant)\n\nReturns an in-place mutated individual with a two random elements of the genome are swapped.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.scramble","page":"Mutation","title":"Evolutionary.scramble","text":"scramble(recombinant)\n\nReturns an in-place mutated individual with elements, on a random arbitrary length segment of the genome, been scrambled.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.shifting","page":"Mutation","title":"Evolutionary.shifting","text":"shifting(recombinant)\n\nReturns an in-place mutated individual with a random arbitrary length segment of the genome been shifted to an arbitrary position.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Base.replace","page":"Mutation","title":"Base.replace","text":"replace(pool,[minchange=1])(recombinant)\n\nReplacement mutation operator changes an arbitrary number, no smaller then minchange, of elements in the individual by replacing them with elements from the predefined pool that are not in the individual.\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Differential-Evolution","page":"Mutation","title":"Differential Evolution","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"Evolutionary.differentiation","category":"page"},{"location":"mutation/#Evolutionary.differentiation","page":"Mutation","title":"Evolutionary.differentiation","text":"differentiation(recombinant, mutators; F = 1.0)\n\nReturns an in-place differently mutated individual x^prime from recombinant x  by mutators xi_1 ldots xi_n  as follows\n\nx^prime = x + sum_i=1^n2 F (xi_2i-1 - xi_2i)\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Genetic-Programming","page":"Mutation","title":"Genetic Programming","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"subtree\npoint\nhoist\nshrink","category":"page"},{"location":"mutation/#Evolutionary.subtree","page":"Mutation","title":"Evolutionary.subtree","text":"subtree(method::TreeGP; growth::Real = 0.1)\n\nReturns an in-place expression mutation function that performs mutation of an arbitrary expression subtree with a randomly generated one [5].\n\nParameters:\n\ngrowth: Growth restriction on the offspring in comparison to the parent.           The offspring cannot be more than growth% deeper than its parent.  (default: 0.0)\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.point","page":"Mutation","title":"Evolutionary.point","text":"point(method::TreeGP)\n\nReturns an in-place expression mutation function that replaces an arbitrary node in the tree by the randomly selected one. Node replacement mutation is similar to bit string mutation in that it randomly changes a point in the individual. To ensure the tree remains legal, the replacement node has the same number of arguments as the node it is replacing [6].\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.hoist","page":"Mutation","title":"Evolutionary.hoist","text":"hoist(method::TreeGP)\n\nReturns an in-place expression mutation function that creates a new offspring individual which is copy of a randomly chosen subtree of the parent. Thus, the offspring will be smaller than the parent and will have a different root node [7].\n\n\n\n\n\n","category":"function"},{"location":"mutation/#Evolutionary.shrink","page":"Mutation","title":"Evolutionary.shrink","text":"shrink(method::TreeGP)\n\nReturns an in-place expression mutation function that replaces a randomly chosen subtree with a randomly created terminal. This is a special case of subtree mutation where the replacement tree is a terminal. As with hoist mutation, it is motivated by the desire to reduce program size [8].\n\n\n\n\n\n","category":"function"},{"location":"mutation/#References","page":"Mutation","title":"References","text":"","category":"section"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[1]: Mühlenbein, H. and Schlierkamp-Voosen, D., \"Predictive Models for the Breeder Genetic Algorithm: I. Continuous Parameter Optimization\", Evolutionary Computation, 1 (1), 25-49, 1993.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[2]: Yao, Xin, and Yong Liu, \"Fast evolution strategies\", In International Conference on Evolutionary Programming, 149-161, Springer, 1997.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[3]: K. Deep, M. Thakur, \"A new crossover operator for real coded genetic algorithms\", Applied Mathematics and Computation 188, 895-912, 2007.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[4]: K. Deep, K. P. Singh, M. L. Kansal, and C. Mohan, \"A real coded  genetic algorithm for solving integer and mixed integer optimization problems\", Appl. Math. Comput. 212, 505-518, 2009","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[5]: K. E. Kinnear, Jr., \"Evolving a sort: Lessons in genetic programming\", In Proceedings of the 1993 International Conference on Neural Networks, vol 2, 881-888, IEEE Press, 1993.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[6]: B. McKay, M. J. Willis, and G. W. Barton., \"Using a tree structured genetic algorithm to perform symbolic regression\", GALESIA, vol 414, 487-492, 1995.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[7]: K. E. Kinnear, Jr., \"Fitness landscapes and difficulty in genetic programming\", In Proceedings of the 1994 IEEE World Conference on Computational Intelligence, vol 1, 142-147, IEEE Press, 1994.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[8]: P. J. Angeline, \"An investigation into the sensitivity of genetic programming to the frequency of leaf selection during subtree crossover\", Genetic Programming 1996: Proceedings of the First Annual Conference, 21–29, 1996.","category":"page"},{"location":"mutation/","page":"Mutation","title":"Mutation","text":"[9]: K. Deb, R. B. Agrawal, \"Simulated Binary Crossover for Continuous Search Space\", Complex Syst., 9., 1995","category":"page"},{"location":"gp/#Genetic-Programming","page":"Genetic Programming","title":"Genetic Programming","text":"","category":"section"},{"location":"gp/","page":"Genetic Programming","title":"Genetic Programming","text":"TreeGP","category":"page"},{"location":"gp/#Evolutionary.TreeGP","page":"Genetic Programming","title":"Evolutionary.TreeGP","text":"Implementation of Koza-type (tree-based) Genetic Programming\n\nThe constructor takes following keyword arguments:\n\npopulationSize: The size of the population\nterminals: A dictionary of terminals with their their corresponding dimensionality\nThis dictionary contains (Terminal, Int) pairs\nThe terminals can be any symbols (variables), constat values, or 0-arity functions.\nfunctions: A collection of functions with their corresponding arity.\nThis dictionary contains (Function, Int) pairs\ninitialization: A strategy for population initialization (default: :grow)\nPossible values: :grow and :full\nmindepth: Minimal depth of the expression (default: 0)\nmaxdepth: Maximal depth of the expression (default: 3)\nsimplify: An expression simplification function (default: :nothing)\noptimizer: An evolutionary optimizer used for evolving the expressions (default: GA)\nUse mutation and crossover parameters to specify GP-related mutation operation.\nUse selection parameter to specify the offspring selection procedure\n\n\n\n\n\n","category":"type"},{"location":"gp/#Description","page":"Genetic Programming","title":"Description","text":"","category":"section"},{"location":"gp/","page":"Genetic Programming","title":"Genetic Programming","text":"The Genetic Programming is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs. It is essentially a heuristic search technique, i.e. searching for an optimal or at least suitable program among the space of all programs[1].","category":"page"},{"location":"gp/#Auxiliary-Functions","page":"Genetic Programming","title":"Auxiliary Functions","text":"","category":"section"},{"location":"gp/","page":"Genetic Programming","title":"Genetic Programming","text":"Evolutionary.Expression\nEvolutionary.randterm\nEvolutionary.simplify!","category":"page"},{"location":"gp/#Evolutionary.Expression","page":"Genetic Programming","title":"Evolutionary.Expression","text":"Julia expression wrapper\n\n\n\n\n\n","category":"type"},{"location":"gp/#Evolutionary.randterm","page":"Genetic Programming","title":"Evolutionary.randterm","text":"randterm(t::TreeGP)\n\nReturns a random terminal given the specification from the TreeGP object t.\n\n\n\n\n\n","category":"function"},{"location":"gp/#Evolutionary.simplify!","page":"Genetic Programming","title":"Evolutionary.simplify!","text":"simplify!(expr)\n\nSimplify an algebraic expression\n\n\n\n\n\n","category":"function"},{"location":"gp/#References","page":"Genetic Programming","title":"References","text":"","category":"section"},{"location":"gp/","page":"Genetic Programming","title":"Genetic Programming","text":"[1]: John R. Koza, \"Genetic Programming: On the Programming of Computers by Means of Natural Selection\", MIT Press, 1992.","category":"page"},{"location":"moea/#Multi-objective-EA","page":"Multi-objective EA","title":"Multi-objective EA","text":"","category":"section"},{"location":"moea/","page":"Multi-objective EA","title":"Multi-objective EA","text":"NSGA2","category":"page"},{"location":"moea/#Evolutionary.NSGA2","page":"Multi-objective EA","title":"Evolutionary.NSGA2","text":"Nondominated Sorting Genetic Algorithm (NSGA-II) for Multi-objective Optimization\n\nThe constructor takes following keyword arguments:\n\npopulationSize: The size of the population\ncrossoverRate: The fraction of the population at the next generation, that is created by the crossover function\nmutationRate: Probability of chromosome to be mutated\nselection: Selection function (default: tournament)\ncrossover: Crossover function (default: SBX)\nmutation: Mutation function (default: PLM)\n\n\n\n\n\n","category":"type"},{"location":"moea/#Description","page":"Multi-objective EA","title":"Description","text":"","category":"section"},{"location":"moea/","page":"Multi-objective EA","title":"Multi-objective EA","text":"Multi-objective optimization is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously. Evolutionary algorithms are popular approaches to generating Pareto optimal solutions to a multi-objective optimization problem by appling Pareto-based ranking schemes, such as the Non-dominated Sorting Genetic Algorithm-II (NSGA-II)[1].","category":"page"},{"location":"moea/#Auxiliary-Functions","page":"Multi-objective EA","title":"Auxiliary Functions","text":"","category":"section"},{"location":"moea/","page":"Multi-objective EA","title":"Multi-objective EA","text":"Evolutionary.nondominatedsort!\nEvolutionary.dominate\nEvolutionary.dominations\nEvolutionary.crowding_distance!\nEvolutionary.gd\nEvolutionary.igd\nEvolutionary.spread","category":"page"},{"location":"moea/#Evolutionary.nondominatedsort!","page":"Multi-objective EA","title":"Evolutionary.nondominatedsort!","text":"nondominatedsort!(R, F)\n\nCalculate fronts for fitness values F, and store ranks of the individuals into R.\n\n\n\n\n\n","category":"function"},{"location":"moea/#Evolutionary.dominate","page":"Multi-objective EA","title":"Evolutionary.dominate","text":"dominate(p, q)\n\nReturns 1 if p is dominated by q, -1 if otherwise, and 0 if dominance cannot be determined.\n\n\n\n\n\n","category":"function"},{"location":"moea/#Evolutionary.dominations","page":"Multi-objective EA","title":"Evolutionary.dominations","text":"dominations(P::AbstractVector)\n\nReturns a domination matrix of all elements in the input collection P.\n\n\n\n\n\n","category":"function"},{"location":"moea/#Evolutionary.crowding_distance!","page":"Multi-objective EA","title":"Evolutionary.crowding_distance!","text":"crowding_distance!((C, F, fronts)\n\nCalculate crowding distance for individuals and save the results into C given the fitness values F and collection of fronts.\n\n\n\n\n\n","category":"function"},{"location":"moea/#Evolutionary.gd","page":"Multi-objective EA","title":"Evolutionary.gd","text":"gd(A,R)\n\nCalculate a generational distance between set A and the refernce set R. This metric measures the convergence, i.e. closeness of the non-dominated solutions to the Pareto front, of a population.\n\nNote: Parameters are column-major matrices.\n\n\n\n\n\n","category":"function"},{"location":"moea/#Evolutionary.igd","page":"Multi-objective EA","title":"Evolutionary.igd","text":"igd(S,R)\n\nCalculate an inverted generational distance, gd, between set S and the refernce set R. Parameters are column-major matrices.\n\n\n\n\n\n","category":"function"},{"location":"moea/#Evolutionary.spread","page":"Multi-objective EA","title":"Evolutionary.spread","text":"spread(S,R)\n\nReturns a diversity metric of a population of set S to the refernce set R.\n\n\n\n\n\n","category":"function"},{"location":"moea/#References","page":"Multi-objective EA","title":"References","text":"","category":"section"},{"location":"moea/","page":"Multi-objective EA","title":"Multi-objective EA","text":"[1]: Deb, K. et al., \"A fast and elitist multiobjective genetic algorithm: NSGA-II\". IEEE Transactions on Evolutionary Computation, 2002.","category":"page"},{"location":"dev/#Development","page":"Development","title":"Development","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"CurrentModule = Evolutionary","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"If you are contributing a new algorithm to this package, you need to know an internal API which allows to add a new algorithm without considerable changes to overall structure of the package.","category":"page"},{"location":"dev/#Adding-an-algorithm","page":"Development","title":"Adding an algorithm","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"If you're contributing a new algorithm, you shouldn't need to touch any of the code in src/api/optimize.jl. You should rather add a file named (solver is the name of the solver) algo.jl in src, and make sure that you define an optimizer parameters and state types, initial_population that initializes a population of individual objects, a state type that holds all variables that are (re)used throughout the iterative procedure, an initial_state that initializes such a state, and an update_state! method that does the actual work.","category":"page"},{"location":"dev/#Algorithm","page":"Development","title":"Algorithm","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"Every optimization algorithm have to implement an algorithm parameters type derived from  AbstractOptimizer type,  e.g. struct Algo <: AbstractOptimizer end, with appropriate fields, a default constructor with a keyword for each field.","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"Function initial_state returns an initial state for the algorithm, see State section. Function update_state! returns a Bool value. If the state update is successfully completed then the function returns false, otherwise true.","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"AbstractOptimizer\ninitial_state","category":"page"},{"location":"dev/#Evolutionary.AbstractOptimizer","page":"Development","title":"Evolutionary.AbstractOptimizer","text":"Abstract evolutionary optimizer algorithm\n\n\n\n\n\n","category":"type"},{"location":"dev/#Evolutionary.initial_state","page":"Development","title":"Evolutionary.initial_state","text":"Initialization of ES algorithm state\n\n\n\n\n\nInitialization of CMA-ES algorithm state\n\n\n\n\n\nInitialization of GA algorithm state\n\n\n\n\n\nInitialization of NSGA2 algorithm state\n\n\n\n\n\nInitialization of DE algorithm state\n\n\n\n\n\nInitialization of GP algorithm state\n\n\n\n\n\n","category":"function"},{"location":"dev/#State","page":"Development","title":"State","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"Every optimization algorithm have to implement a state type derived from AbstractOptimizerState type, e.g. struct AlgoState <: AbstractOptimizerState end. All derived types should implement value and minimizer functions","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"AbstractOptimizerState\nvalue(::AbstractOptimizerState)\nminimizer(::AbstractOptimizerState)\nterminate(::AbstractOptimizerState)","category":"page"},{"location":"dev/#Evolutionary.AbstractOptimizerState","page":"Development","title":"Evolutionary.AbstractOptimizerState","text":"Abstract type for defining an optimizer state\n\nEvery algorithm have to implement a state type derived from this abstract type.\n\n\n\n\n\n","category":"type"},{"location":"dev/#NLSolversBase.value-Tuple{Evolutionary.AbstractOptimizerState}","page":"Development","title":"NLSolversBase.value","text":"value(state)\n\nReturns a minimum value of the current state.\n\n\n\n\n\n","category":"method"},{"location":"dev/#Evolutionary.minimizer-Tuple{Evolutionary.AbstractOptimizerState}","page":"Development","title":"Evolutionary.minimizer","text":"value(state)\n\nReturns a minimizer object in the current state.\n\n\n\n\n\n","category":"method"},{"location":"dev/#Evolutionary.terminate-Tuple{Evolutionary.AbstractOptimizerState}","page":"Development","title":"Evolutionary.terminate","text":"terminate(state)\n\nReturns true if the state requires early termination.\n\n\n\n\n\n","category":"method"},{"location":"dev/#Population","page":"Development","title":"Population","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"The evolutionary algorithms require a collection of individuals, population, which the algorithm constantly modifies. The population collection type must be derived from the AbstractVector type. Function initial_population is used for implementing a strategy of population collection initialization.","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"The initial_population must accept two parameters:","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"method, an algorithm object derived from AbstractOptimizer type\nindividual, a description of an individual template used to create the population","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"Following population initialization strategies are available:","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"initial_population","category":"page"},{"location":"dev/#Evolutionary.initial_population","page":"Development","title":"Evolutionary.initial_population","text":"initial_population(method, individual::AbstractVector)\n\nInitialize population by replicating the inividual vector.\n\n\n\n\n\ninitial_population(method, individuals::AbstractVector{<:AbstractVector})\n\nInitialize population from the collection of inividuals vectors.\n\n\n\n\n\ninitial_population(method, individual::Function)\n\nInitialize population from the inividual function which returns an individual object.\n\n\n\n\n\ninitial_population(method, individual::AbstractMatrix)\n\nInitialize population by replicating the inividual matrix.\n\n\n\n\n\ninitial_population(method, bounds::ConstraintBounds)\n\nInitialize a random population within the individual bounds.\n\n\n\n\n\ninitial_population(m::TreeGP, expr::{Expr,Nothing}=nothing)\n\nInitialize a random population of expressions derived from expr.\n\n\n\n\n\n","category":"function"},{"location":"dev/#Constraints","page":"Development","title":"Constraints","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"All constraints derived from the AbstractConstraints abstract type. Usually the derived type wraps a ConstraintBounds object, so the","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"Following methods can be overridden for the derived types:","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"value(::AbstractConstraints, x)","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"Following auxiliary functions are available for every derived type of AbstractConstraints.","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"isfeasible(::AbstractConstraints, x)","category":"page"},{"location":"dev/#Evolutionary.isfeasible-Tuple{NLSolversBase.AbstractConstraints, Any}","page":"Development","title":"Evolutionary.isfeasible","text":"isfeasible(c::AbstractConstraints, x) -> Bool\n\nReturn true if point x is feasible, given the constraints object c.\n\n\n\n\n\n","category":"method"},{"location":"dev/","page":"Development","title":"Development","text":"Package provides following additional constrains implementations.","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"Evolutionary.NoConstraints\nMixedTypePenaltyConstraints","category":"page"},{"location":"dev/#Evolutionary.NoConstraints","page":"Development","title":"Evolutionary.NoConstraints","text":"Type for an empty set of constratins\n\n\n\n\n\n","category":"type"},{"location":"dev/#Evolutionary.MixedTypePenaltyConstraints","page":"Development","title":"Evolutionary.MixedTypePenaltyConstraints","text":"This type provides an additional type constraints on the varaibles required for mixed integer optimization problmes.\n\n\n\n\n\n","category":"type"},{"location":"dev/#Objective","page":"Development","title":"Objective","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"Internally, the objective function is wrapped into EvolutionaryObjective type object.","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"Evolutionary.EvolutionaryObjective\nEvolutionary.EvolutionaryObjective(f, x::AbstractArray)\nEvolutionary.EvolutionaryObjective(f, x::Expr)\nEvolutionary.ismultiobjective","category":"page"},{"location":"dev/#Evolutionary.EvolutionaryObjective","page":"Development","title":"Evolutionary.EvolutionaryObjective","text":"Wrapper around an objective function (compatible with NLSolversBase).\n\n\n\n\n\n","category":"type"},{"location":"dev/#Evolutionary.EvolutionaryObjective-Tuple{Any, AbstractArray}","page":"Development","title":"Evolutionary.EvolutionaryObjective","text":"EvolutionaryObjective(f, x[, F])\n\nConstructor for an objective function object around the function f with initial paramter x, and objective value F.\n\n\n\n\n\n","category":"method"},{"location":"dev/#Evolutionary.EvolutionaryObjective-Tuple{Any, Expr}","page":"Development","title":"Evolutionary.EvolutionaryObjective","text":"EvolutionaryObjective(f, x::Expr[, F])\n\nConstructor for an objective object for a Julia evaluatable expression.\n\n\n\n\n\n","category":"method"},{"location":"dev/#Evolutionary.ismultiobjective","page":"Development","title":"Evolutionary.ismultiobjective","text":"ismultiobjective(objfun)\n\nReturn true if the function is multiobjective objective.\n\n\n\n\n\n","category":"function"},{"location":"dev/#Parallelization","page":"Development","title":"Parallelization","text":"","category":"section"},{"location":"dev/","page":"Development","title":"Development","text":"For additional modes of parallelization of the objective function evaluation, add overrides of the value! function. By default, the fitness of the population is calculated by the following function:","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"function value!(obj::EvolutionaryObjective{TC,TF,TX,Val{:serial}}, fitness, population::AbstractVector{IT}) where {IT}\n    n = length(xs)\n    for i in 1:n\n        F[i] = value(obj, xs[i])\n    end\n    F\nend","category":"page"},{"location":"dev/","page":"Development","title":"Development","text":"The first symbolic value type parameter, :serial, corresponds to the default value of the parallelization of the Options object. Any additional overrides with different value type parameters will be triggered by specifying a corresponded value type symbol in the Options.parallelization field. A multi-threaded override of the above evaluation is provided.","category":"page"},{"location":"es/#Evolution-Strategies","page":"Evolution Strategy","title":"Evolution Strategies","text":"","category":"section"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"ES","category":"page"},{"location":"es/#Evolutionary.ES","page":"Evolution Strategy","title":"Evolutionary.ES","text":"Implementation of Evolution Strategy: (μ/ρ(+/,)λ)-ES\n\nThe constructor takes following keyword arguments:\n\ninitStrategy: an initial strategy description, (default: empty)\nrecombination: ES recombination function for population (default: first), see Crossover\nsrecombination: ES recombination function for strategies (default: first), see Crossover\nmutation: Mutation function for population (default: first)\nsmutation: Mutation function for strategies (default: identity)\nμ/mu: the number of parents\nρ/rho: the mixing number, ρ ≤ μ, (i.e., the number of parents involved in the procreation of an offspring)\nλ/lambda: the number of offspring\nselection: the selection strategy :plus or :comma (default: :plus)\n\n\n\n\n\n","category":"type"},{"location":"es/#Description","page":"Evolution Strategy","title":"Description","text":"","category":"section"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"The Evolution Strategy  is  is an optimization technique based on ideas of evolution.","category":"page"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"Evolution strategies use natural problem-dependent representations, and primarily Mutation and Selection, as search operators.","category":"page"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"The canonical versions of the ES are denoted by (sigmarholambda)-ES and (μ/ρ+λ)-ES, respectively. Here mu denotes the number of parents, rho leq mu the mixing number (i.e., the number of parents involved in the procreation of an offspring), and lambda the number of offspring. The parents are deterministically selected (i.e., deterministic survivor selection) from the (multi-)set of either the offspring, referred to as comma-selection (mu  lambda must hold), or both the parents and offspring, referred to as plus-selection [1].","category":"page"},{"location":"es/#Strategies","page":"Evolution Strategy","title":"Strategies","text":"","category":"section"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"The evolution strategy algorithm provides, for every the optimized object parameter vector x, a set of strategy parameters s. The strategy is used to create an offspring x^prime is generated from the population individual x on every iteration of the algorithm by applying a mutation operation:","category":"page"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"x^prime = mutation(x s)","category":"page"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"A strategy s usually has a parameter, e.g. sigma, that controls the strength of the object parameter mutation. For example, if the mutation operation is gaussian then the sigma is simply the standard deviation of the normally distributed random component.","category":"page"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"List of ES strategies:","category":"page"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"AbstractStrategy\nNoStrategy\nIsotropicStrategy\nIsotropicStrategy(::Integer)\nAnisotropicStrategy\nAnisotropicStrategy(::Integer)","category":"page"},{"location":"es/#Evolutionary.AbstractStrategy","page":"Evolution Strategy","title":"Evolutionary.AbstractStrategy","text":"Abstract evolution strategy\n\nAll evolution strategies must be derived from this type.\n\n\n\n\n\n","category":"type"},{"location":"es/#Evolutionary.NoStrategy","page":"Evolution Strategy","title":"Evolutionary.NoStrategy","text":"Empty evolution strategy\n\n\n\n\n\n","category":"type"},{"location":"es/#Evolutionary.IsotropicStrategy","page":"Evolution Strategy","title":"Evolutionary.IsotropicStrategy","text":"Isotropic evolution strategy\n\nThis strategy has one mutation parameter for all object parameter components.\n\n\n\n\n\n","category":"type"},{"location":"es/#Evolutionary.IsotropicStrategy-Tuple{Integer}","page":"Evolution Strategy","title":"Evolutionary.IsotropicStrategy","text":"IsotropicStrategy(N)\n\nReturns an isotropic strategy object, which has an one mutation parameter for all object parameter components, with sigma = 10, tau_0 = sqrt2N^-1, tau = sqrt2sqrtN^-1\n\n\n\n\n\n","category":"method"},{"location":"es/#Evolutionary.AnisotropicStrategy","page":"Evolution Strategy","title":"Evolutionary.AnisotropicStrategy","text":"Anisotropic evolution strategy\n\nThis strategy has a mutation parameter for each object parameter component.\n\n\n\n\n\n","category":"type"},{"location":"es/#Evolutionary.AnisotropicStrategy-Tuple{Integer}","page":"Evolution Strategy","title":"Evolutionary.AnisotropicStrategy","text":"AnisotropicStrategy(N)\n\nReturns an anisotropic strategy object, which has an one mutation parameter for each object parameter component, with sigma = 1 ldots 1^N, tau_0 = sqrt2N^-1, tau = sqrt2sqrtN^-1\n\n\n\n\n\n","category":"method"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"See Mutation section for strategy mutation operations.","category":"page"},{"location":"es/#References","page":"Evolution Strategy","title":"References","text":"","category":"section"},{"location":"es/","page":"Evolution Strategy","title":"Evolution Strategy","text":"[1]: http://www.scholarpedia.org/article/Evolution_strategies","category":"page"},{"location":"selection/#Selection","page":"Selection","title":"Selection","text":"","category":"section"},{"location":"selection/","page":"Selection","title":"Selection","text":"Selection is a genetic operator used in EAs for selecting potentially useful solutions from a population for later breeding. The EAs are stochastic search methods using the concepts of Mendelian genetics and Darwinian evolution. According to Darwin's evolution theory the best ones should survive and create new offspring. There are many methods how to select the best individuals, for example roulette wheel selection, Boltzman selection, tournament selection, rank selection, steady state selection and some others.","category":"page"},{"location":"selection/#Selection-Interface","page":"Selection","title":"Selection Interface","text":"","category":"section"},{"location":"selection/","page":"Selection","title":"Selection","text":"All selection algorithms have following call interface selection(fitness, N) where fitness is the vector of population fitness values, of size M, and N is the number of selected individuals. The selection function returns a vector of integer indexes of selected individuals, of size N with indexes in range 1M.","category":"page"},{"location":"selection/","page":"Selection","title":"Selection","text":"Note: Some of the selection algorithms implemented as function closures, in order to provide additional parameters to the specified above selection interface.","category":"page"},{"location":"selection/#Genetic-Algorithm","page":"Selection","title":"Genetic Algorithm","text":"","category":"section"},{"location":"selection/","page":"Selection","title":"Selection","text":"ranklinear\nuniformranking\nroulette\nrouletteinv\nsus\nsusinv\ntruncation\ntournament","category":"page"},{"location":"selection/#Evolutionary.ranklinear","page":"Selection","title":"Evolutionary.ranklinear","text":"ranklinear(sp::Real)\n\nReturns a rank-based fitness selection function, see Selection Interface, with the selective pressure value sp.\n\nIn rank-based fitness selection, the population is sorted according to the objective values. The fitness assigned to each individual depends only on its position in the individuals rank and not on the actual objective value [1].\n\nConsider M the number of individuals in the population, P the position of an individual in this population (least fit individual has P = 1, the fittest individual P = M) and SP the selective pressure. The fitness value for an individual is calculated as:\n\nFitness(P) = 2 - SP + frac2(SP - 1)(P - 1)(M - 1)\n\nLinear ranking allows values of selective pressure in [1.0, 2.0].\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.uniformranking","page":"Selection","title":"Evolutionary.uniformranking","text":"uniformranking(μ)\n\nReturns a (μ, λ)-uniform ranking selection function, see Selection Interface with the best individuals parameter μ.\n\nIn uniform ranking, the best mu individuals are assigned a selection probability of 1mu while the rest them are discarded [2].\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.roulette","page":"Selection","title":"Evolutionary.roulette","text":"roulette(fitness)\n\nRoulette wheel (fitness proportionate, FPS) selection from fitness collection.\n\nIn roulette selection, the fitness level is used to associate a probability of selection with each individual. If f_i is the fitness of individual i in the population, its probability of being selected is p_i = fracf_iSigma_j=1^M f_j, where M is the number of individuals in the population.\n\nNote: Best used in maximization context.\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.rouletteinv","page":"Selection","title":"Evolutionary.rouletteinv","text":"rouletteinv(fitness)\n\nFitness proportionate selection (FPS) or roulette wheel for inverse fitness values. Best used in minimization to 0.\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.sus","page":"Selection","title":"Evolutionary.sus","text":"sus(fitness, N)\n\nStochastic universal sampling (SUS) provides zero bias and minimum spread [3]. SUS is a development of fitness proportionate selection (FPS). Using a comb-like ruler, SUS starts from a small random number, and chooses the next candidates from the rest of population remaining, not allowing the fittest members to saturate the candidate space. The individuals are mapped to contiguous segments of a line, such that each individual's segment is equal in size to its fitness exactly as in roulette-wheel selection. Here equally spaced pointers are placed over the line as many as there are individuals to be selected.\n\nConsider N the number of individuals to be selected, then the distance between the pointers are 1N and the position of the first pointer is given by a randomly generated number in the range 0 1N.\n\nNote: Best used in maximization context.\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.susinv","page":"Selection","title":"Evolutionary.susinv","text":"susinv(fitness)\n\nInverse fitness SUS. Best used in minimization to 0.\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.truncation","page":"Selection","title":"Evolutionary.truncation","text":"truncation(fitness, N)\n\nTruncation selection returns first N of best fitness individuals\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.tournament","page":"Selection","title":"Evolutionary.tournament","text":"Tournament selection\n\n\n\n\n\n","category":"function"},{"location":"selection/#Differential-Evolution","page":"Selection","title":"Differential Evolution","text":"","category":"section"},{"location":"selection/","page":"Selection","title":"Selection","text":"random\npermutation\nrandomoffset\nbest","category":"page"},{"location":"selection/#Evolutionary.random","page":"Selection","title":"Evolutionary.random","text":"random(fitness, N)\n\nReturns a collection on size N of uniformly selected individuals from the population.\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.permutation","page":"Selection","title":"Evolutionary.permutation","text":"permutation(fitness, N)\n\nReturns a permutation on size N of the individuals from the population.\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.randomoffset","page":"Selection","title":"Evolutionary.randomoffset","text":"randomoffset(fitness, N)\n\nReturns a cycle selection on size N from an arbitrary position.\n\n\n\n\n\n","category":"function"},{"location":"selection/#Evolutionary.best","page":"Selection","title":"Evolutionary.best","text":"best(fitness, N)\n\nReturns a collection of best individuals of size N.\n\n\n\n\n\n","category":"function"},{"location":"selection/#References","page":"Selection","title":"References","text":"","category":"section"},{"location":"selection/","page":"Selection","title":"Selection","text":"[1]: Baker J.E., Adaptive selection methods for genetic algorithms, In Proceedings of International Conference on Genetic Algorithms and Their Applications, pp. 100-111, 1985.","category":"page"},{"location":"selection/","page":"Selection","title":"Selection","text":"[2]: Schwefel H.P., Evolution and Optimum Seeking, Wiley, New York, 1995.","category":"page"},{"location":"selection/","page":"Selection","title":"Selection","text":"[3]: Baker, J. E., Reducing Bias and Inefficiency in the Selection Algorithm. In [ICGA2], pp. 14-21, 1987.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"using Evolutionary","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"The nonlinear constrained optimization interface in Evolutinary assumes that the user can write the optimization problem as follows:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"min_xinmathbbR^n f(x) quad textsuch that\nl_x leq phantomc(xphantom) leq u_x \nl_c leq c(x) leq u_c","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"For equality constraints on x_j or c(x)_j you set those particular entries of bounds to be equal, l_j=u_j. Likewise, setting l_j=-infty or u_j=infty means that the  constraint is unbounded from below or above respectively.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Following examples show how to use constraints to optimize the Booth function. The function is defined as follows:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"f(x)=(x[1]+2x[2]-7)^2+(2x[1]+x[2]-5)^2 # Booth","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"The function is usually evaluated on the square x_i  -10 10, for all i = 1 2. The global minimum on this function is located at (13).","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"ga = GA(populationSize=100,selection=uniformranking(3),\n        mutation=gaussian(),crossover=uniformbin())\nx0 = [0., 0.]\nresults = Evolutionary.optimize(f, x0, ga)","category":"page"},{"location":"constraints/#Box-Constrained-Optimization","page":"Constraints","title":"Box Constrained Optimization","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"We want to optimize the Booth function in the box 05 leq x_i leq 20, starting from the point x_0=(11).","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Reusing our Booth example from above, boxed minimization is performed by providing vectors of lower and upper bounds as follows:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"lower = [0.5, 0.5]\nupper = [2.0, 2.0]\nx0 = [1., 1.]\nresults = Evolutionary.optimize(f, BoxConstraints(lower, upper), x0, ga)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"The box constraints can be also defined using BoxConstraints object.","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"BoxConstraints","category":"page"},{"location":"constraints/#Evolutionary.BoxConstraints","page":"Constraints","title":"Evolutionary.BoxConstraints","text":"This type encodes box constraints for the optimization function parameters.\n\nThe constructor takes following arguments:\n\nlower is the vector of value lower bounds\nupper is the vector of value upper bounds\n\nNote: Sizes of the lower and upper bound vectors must be equal.\n\n\n\n\n\n","category":"type"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"cnst = BoxConstraints([0.5, 0.5], [2.0, 2.0])","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"This object can be passed as a parameter to the optimization call, Evolutionary.optimize:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"results = Evolutionary.optimize(f, cnst, x0, ga) # or Evolutionary.optimize(f, cnst, ga)","category":"page"},{"location":"constraints/#Penalty-Constrained-Optimization","page":"Constraints","title":"Penalty Constrained Optimization","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"For the penalty constrained optimization, any value and linear/nonlinear constraints are transformed into the penalty to the minimized fitness function. In order to provide linear/nonlinear constraints to an optimization problem, you can use the following penalty constraint algorithm:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"PenaltyConstraints","category":"page"},{"location":"constraints/#Evolutionary.PenaltyConstraints","page":"Constraints","title":"Evolutionary.PenaltyConstraints","text":"This type encodes constraints as the following additional penalty for an objective function:\n\np(x) = sum^n_i=1 r_i max(0 g_i(x))^2\n\nwhere r_i is a penalty value for ith constraint, and g_i(x) is an inequality constraint. The equality constraints h_i(x) = 0 are transformed to inequality constraints as follows:\n\nh(x) - epsilon  leq 0\n\nThe constructor takes following arguments:\n\npenalties: a vector of penalty values per constraint (optional)\nlx: a vector of value lower bounds\nux: a vector of value upper bounds\nlc: a vector of constrain function lower bounds\nuc: a vector of constrain function upper bounds\nc: a constraint function which returns a constrain values\n\n\n\n\n\n","category":"type"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"We want to minimize the following function f(xy) = 3x+9y that is subject to constraints sqrt(xy) geq 100 and xy geq 0. The minimum of this function is near (17341 578). We begin  by defining constraints as follows:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"# x, y ≥ 0\nlx = [0.0, 0.0] # lower bound for values\nux = [Inf, Inf] # upper bound for values\n# √xy ≥ 100\nc(x) = [ prod(map(e->sqrt(e>0 ? e : 0.0), x)) ] # negative values are zeroed\nlc   = [100.0] # lower bound for constraint function\nuc   = [ Inf ]   # upper bound for constraint function\ncon = PenaltyConstraints(100.0, lx, ux, lc, uc, c) # first parameter is a penalty value","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"Now, we define the fitness function, an initial individual structure, and algorithm parameters; then we perform minimization as follows:","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"f(x) = 3x[1]+9x[2] # fitness function\nx0 = [1., 1.] # individual\nga = GA(populationSize=100,selection=tournament(7),\n        mutation=gaussian(),crossover=intermediate(2))\nresults = Evolutionary.optimize(f, con, x0, ga)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"We can use worst fitness constraint algorithm which doesn't require to specify the constraint penalty value","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"WorstFitnessConstraints","category":"page"},{"location":"constraints/#Evolutionary.WorstFitnessConstraints","page":"Constraints","title":"Evolutionary.WorstFitnessConstraints","text":"This type encodes constraints as the following additional penalty for an objective function:\n\np(x) = f_worst + sum^n_i=1 g_i(x)\n\nif x is not feasible, otherwise no penalty is applied.\n\nThe constructor takes following arguments:\n\nlx: a vector of value lower bounds\nux: a vector of value upper bounds\nlc: a vector of constrain function lower bounds\nuc: a vector of constrain function upper bounds\nc: a constraint function which returns a constrain values\n\n\n\n\n\n","category":"type"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"con = WorstFitnessConstraints(lx, ux, lc, uc, c)","category":"page"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"results = Evolutionary.optimize(f, con, x0, ga)","category":"page"},{"location":"constraints/#Auxiliary-Functions","page":"Constraints","title":"Auxiliary Functions","text":"","category":"section"},{"location":"constraints/","page":"Constraints","title":"Constraints","text":"value(c::Evolutionary.AbstractConstraints, x)\nisfeasible\npenalty\npenalty!\napply!\nbounds","category":"page"},{"location":"constraints/#NLSolversBase.value-Tuple{NLSolversBase.AbstractConstraints, Any}","page":"Constraints","title":"NLSolversBase.value","text":"value(c::AbstractConstraints, x)\n\nReturn a values of constraints for a variable x given the set of constraints in the object c.\n\n\n\n\n\n","category":"method"},{"location":"constraints/#Evolutionary.isfeasible","page":"Constraints","title":"Evolutionary.isfeasible","text":"isfeasible(bounds::ConstraintBounds, x) -> Bool\n\nReturn true if point x is feasible, given the bounds object with bounds lx, ux, lc, and uc. x is feasible if\n\nlx[i] <= x[i] <= ux[i]\nlc[i] <= c(x)[i] <= uc[i]\n\nfor all possible i.\n\n\n\n\n\nisfeasible(c::AbstractConstraints, x) -> Bool\n\nReturn true if point x is feasible, given the constraints object c.\n\n\n\n\n\n","category":"function"},{"location":"constraints/#Evolutionary.penalty","page":"Constraints","title":"Evolutionary.penalty","text":"penalty(constraints, x)\n\nCalculate a penalty for the variable x given the set of constraints.\n\n\n\n\n\n","category":"function"},{"location":"constraints/#Evolutionary.penalty!","page":"Constraints","title":"Evolutionary.penalty!","text":"penalty!(fitness, constraints, population)\n\nSet a penalty to the fitness given the set of constraints and population.\n\n\n\n\n\n","category":"function"},{"location":"constraints/#Evolutionary.apply!","page":"Constraints","title":"Evolutionary.apply!","text":"apply!(c::AbstractConstraints, x)\n\nAppliy constrains c to a variable x, and return the variable.\n\n\n\n\n\n","category":"function"},{"location":"constraints/#Evolutionary.bounds","page":"Constraints","title":"Evolutionary.bounds","text":"bounds(c::AbstractConstraints)\n\nReturn bounds for the constraint c.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Crossover","page":"Crossover","title":"Crossover","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"In genetic algorithms and evolutionary computation, crossover, also called recombination, is a genetic operator used to combine the genetic information of two parents to generate new offspring.","category":"page"},{"location":"crossover/#Recombination-Interface","page":"Crossover","title":"Recombination Interface","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"All recombination operations have following call interface: recombination(i1, i2) where i1 and i2 are the same type individuals that involved in recombination to produce an offspring. The recombination function returns pair of recombined individuals.","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"Note: Some of the selection algorithms implemented as function closures, in order to provide additional parameters for the specified above recombination interface.","category":"page"},{"location":"crossover/#Operations","page":"Crossover","title":"Operations","text":"","category":"section"},{"location":"crossover/#ES-Crossovers","page":"Crossover","title":"ES Crossovers","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"List of the ES strategy recombination operations:","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"average(::Vector{<:AbstractStrategy})","category":"page"},{"location":"crossover/#Evolutionary.average-Tuple{Vector{var\"#s25\"} where var\"#s25\"<:AbstractStrategy}","page":"Crossover","title":"Evolutionary.average","text":"average(ss::Vector{<:AbstractStrategy})\n\nReturns the average value of the mutation parameter sigma of strategies ss.\n\n\n\n\n\n","category":"method"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"List of the ES population recombination operations:","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"average(population::Vector{T}) where {T <: AbstractVector}\nmarriage","category":"page"},{"location":"crossover/#Evolutionary.average-Union{Tuple{Vector{T}}, Tuple{T}} where T<:(AbstractVector{T} where T)","page":"Crossover","title":"Evolutionary.average","text":"average(population)\n\nReturns an one offspring individual of a multi-parent recombination by averaging population.\n\n\n\n\n\n","category":"method"},{"location":"crossover/#Evolutionary.marriage","page":"Crossover","title":"Evolutionary.marriage","text":"marriage(population)\n\nReturns an one offspring individual of a multi-parent recombination by random copying from population.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Binary-Crossovers","page":"Crossover","title":"Binary Crossovers","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"SPX\nTPX\nSHFX\nUX\nBINX\nEXPX\nBSX","category":"page"},{"location":"crossover/#Evolutionary.SPX","page":"Crossover","title":"Evolutionary.SPX","text":"SPX(v1, v2)\n\nSingle point crossover between v1 and v2 individuals.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.TPX","page":"Crossover","title":"Evolutionary.TPX","text":"TPX(v1, v2)\n\nTwo point crossover between v1 and v2 individuals.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.SHFX","page":"Crossover","title":"Evolutionary.SHFX","text":"SHFX(v1, v2)\n\nShuffle crossover between the parents v1 and v2 that performs recombination similar to SPX preliminary shuffling these parents.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.UX","page":"Crossover","title":"Evolutionary.UX","text":"UX(v1, v2)\n\nUniform crossover between v1 and v2 individuals.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.BINX","page":"Crossover","title":"Evolutionary.BINX","text":"BINX(Cr::Real=0.5)\n\nReturns a uniform (binomial) crossover function, see Recombination Interface, function with the probability Cr [2].\n\nThe crossover probability value must be in unit interval, Cr in 01.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.EXPX","page":"Crossover","title":"Evolutionary.EXPX","text":"EXPX(Cr::Real=0.5)\n\nReturns an exponential crossover function, see Recombination Interface, function with the probability Cr [2].\n\nThe crossover probability value must be in unit interval, Cr in 01.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.BSX","page":"Crossover","title":"Evolutionary.BSX","text":"BSX(k::Int)\n\nBinary Subset Crossover[7]. Produces an offspring by first pooling the unique items of the two parents, and then creating each offspring by sampling without  replacement at most k elements from the pool of items.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Real-valued-Crossovers","page":"Crossover","title":"Real-valued Crossovers","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"identity\nDC\nAX\nWAX\nIC\nLC\nHX\nLX\nMILX\nSBX","category":"page"},{"location":"crossover/#Base.identity","page":"Crossover","title":"Base.identity","text":"identity(v1, v2)\n\nReturns the same parameter individuals v1 and v2 as an offspring pair.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.DC","page":"Crossover","title":"Evolutionary.DC","text":"DC(v1, v2)\n\nReturns a randomly assembled offspring and its inverse from the elements of parents v1 and v2.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.AX","page":"Crossover","title":"Evolutionary.AX","text":"AX(v1, v2)\n\nAverage crossover generates an offspring by taking average of the parents v1 and v2. \n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.WAX","page":"Crossover","title":"Evolutionary.WAX","text":"WAX(w::Vector{<:Real})(v1, v2)\n\nReturns a weighted average recombination operation, see Recombination Interface, which generate an offspring as weighted average of the parents v1 and v2 with the weights w.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.IC","page":"Crossover","title":"Evolutionary.IC","text":"IC(d::Real=0.0)\n\nReturns an extended intermediate recombination operation, see Recombination Interface, which generates offspring u and v as\n\nu_i = x_i + alpha_i (y_i - x_i)\nv_i = y_i + alpha_i (x_i - y_i)\n\nwhere alpha_i is chosen uniform randomly in the interval -dd+1.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.LC","page":"Crossover","title":"Evolutionary.LC","text":"LC(d::Real=0.0)\n\nReturns a extended line recombination operation, see Recombination Interface, which generates offspring u and v as\n\nu_i = x_i + alpha (y_i - x_i)\nv_i = y_i + alpha (x_i - y_i)\n\nwhere alpha is chosen uniform randomly in the interval -dd+1.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.HX","page":"Crossover","title":"Evolutionary.HX","text":"HX(x, y)\n\nHeuristic crossover (HX) recombination operation[3] generates offspring u and v as\n\nu = x + r (x - y)\nv = y + r (y - x)\n\nwhere r is chosen uniform randomly in the interval 01).\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.LX","page":"Crossover","title":"Evolutionary.LX","text":"LX(μ::Real = 0.0, b::Real = 0.2)\n\nReturns a Laplace crossover (LX) recombination operation[4], see Recombination Interface.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.MILX","page":"Crossover","title":"Evolutionary.MILX","text":"MILX(μ::Real = 0.0, b_real::Real = 0.15, b_int::Real = 0.35)\n\nReturns a mixed integer Laplace crossover (MI-LX) recombination operation[5], see Recombination Interface.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.SBX","page":"Crossover","title":"Evolutionary.SBX","text":"SBX(pm::Real = 0.5, η::Integer = 2)\n\nReturns a Simulated Binary Crossover (SBX) recombination operation, see Recombination Interface, with the mutation probability pm of the recombinant component, and is the crossover distribution index η[6].\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Combinatorial-Crossovers","page":"Crossover","title":"Combinatorial Crossovers","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"PMX\nOX1\nCX\nOX2\nPOS\nSSX","category":"page"},{"location":"crossover/#Evolutionary.PMX","page":"Crossover","title":"Evolutionary.PMX","text":"PMX(v1, v2)\n\nPartially mapped crossover which maps ordering and values information from the parents v1 and v2 to  the offspring. A portion of one parent is mapped onto a portion of the other parent string and the remaining information is exchanged.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.OX1","page":"Crossover","title":"Evolutionary.OX1","text":"OX1(v1, v2)\n\nOrder crossover constructs an offspring by choosing a substring of one parent and preserving the relative order of the elements of the other parent.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.CX","page":"Crossover","title":"Evolutionary.CX","text":"CX(v1, v2)\n\nCycle crossover creates an offspring from the parents v1 and v2 such that every position is occupied by a corresponding element from one of the parents.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.OX2","page":"Crossover","title":"Evolutionary.OX2","text":"OX2(v1, v2)\n\nOrder-based crossover selects at random several positions in the parent v1, and the order of the elements in the selected positions of the parent v1 is imposed on the parent v2.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.POS","page":"Crossover","title":"Evolutionary.POS","text":"POS(v1, v2)\n\nPosition-based crossover is a modification of the OX1 operator. It selects a random set of positions in the parents v1 and v2, then imposes the position of the selected elements of one parent on the corresponding elements of the other parent.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Evolutionary.SSX","page":"Crossover","title":"Evolutionary.SSX","text":"SSX(v1, v2)\n\nSubset crossover operator creates new offspring by pooling the unique indices of the two parent vectors v1 and v2, and then sampling a set of unique indices from this pool, uniformly at random.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#Tree-(expression)-Crossovers","page":"Crossover","title":"Tree (expression) Crossovers","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"Evolutionary.crosstree","category":"page"},{"location":"crossover/#Evolutionary.crosstree","page":"Crossover","title":"Evolutionary.crosstree","text":"crosstree(t1::Expr, t2::Expr)\n\nPerform an arbitrary subtree swap between the expressions t1 and t2.\n\n\n\n\n\n","category":"function"},{"location":"crossover/#References","page":"Crossover","title":"References","text":"","category":"section"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"[1]: H. Mühlenbein, D. Schlierkamp-Voosen, \"Predictive Models for the Breeder Genetic Algorithm: I. Continuous Parameter Optimization\". Evolutionary Computation, 1 (1), pp. 25-49, 1993.","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"[2]: K. V. Price and R. M. Storn and J. A. Lampinen, \"Differential evolution: A practical approach to global optimization\", Springer, 2005.","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"[3]: Z. Michalewicz, T. Logan,  S. Swaminathan. \"Evolutionary operators for continuous convex parameter spaces.\" Proceedings of the 3rd Annual conference on Evolutionary Programming, 1994.","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"[4]: K. Deep, M. Thakur, \"A new crossover operator for real coded genetic algorithms\", Applied Mathematics and Computation 188, 2007, 895–912","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"[5]: K. Deep, K. P. Singh, M. L. Kansal, and C. Mohan, \"A real coded  genetic algorithm for solving integer and mixed integer optimization problems.\", Appl. Math. Comput. 212, 505-518, 2009","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"[6]: K. Deb, R. B. Agrawal, \"Simulated Binary Crossover for Continuous Search Space\", Complex Syst., 9., 1995","category":"page"},{"location":"crossover/","page":"Crossover","title":"Crossover","text":"[7]: M. A. Wolters, “A Genetic Algorithm for Selection of Fixed-Size Subsets with Application to Design Problems”, J. Stat. Soft., vol. 68, no. 1, pp. 1–18, Nov. 2015.","category":"page"},{"location":"de/#Differential-Evolution","page":"Differential Evolution","title":"Differential Evolution","text":"","category":"section"},{"location":"de/","page":"Differential Evolution","title":"Differential Evolution","text":"DE","category":"page"},{"location":"de/#Evolutionary.DE","page":"Differential Evolution","title":"Evolutionary.DE","text":"Implementation of Differential Evolution: DE/selection/n/recombination\n\nThe constructor takes following keyword arguments:\n\npopulationSize: The size of the population\nF: the differentiation (mutation) scale factor (default: 0.9). It's usually defined in range F in (0 1+\nn: the number of differences used in the perturbation (default: 1)\nselection: the selection strategy function (default: random)\nrecombination: the recombination functions (default: BINX(0.5))\nK: the recombination scale factor (default: 0.5*(F+1))\n\n\n\n\n\n","category":"type"},{"location":"de/#Description","page":"Differential Evolution","title":"Description","text":"","category":"section"},{"location":"de/","page":"Differential Evolution","title":"Differential Evolution","text":"The Differential Evolution is used for multidimensional real-valued functions but does not use the gradient of the problem being optimized, which means DE does not require the optimization problem to be differentiable, as is required by classic optimization methods such as gradient descent and quasi-newton methods. DE can therefore also be used on optimization problems that are not even continuous, are noisy, change over time, etc [1].","category":"page"},{"location":"de/#References","page":"Differential Evolution","title":"References","text":"","category":"section"},{"location":"de/","page":"Differential Evolution","title":"Differential Evolution","text":"[1]: K. V. Price and R. M. Storn and J. A. Lampinen, \"Differential evolution: A practical approach to global optimization\", Springer, 2005.","category":"page"},{"location":"ga/#Genetic-Algorithm","page":"Genetic Algorithm","title":"Genetic Algorithm","text":"","category":"section"},{"location":"ga/","page":"Genetic Algorithm","title":"Genetic Algorithm","text":"GA","category":"page"},{"location":"ga/#Evolutionary.GA","page":"Genetic Algorithm","title":"Evolutionary.GA","text":"Implementation of Genetic Algorithm\n\nThe constructor takes following keyword arguments:\n\npopulationSize: The size of the population\ncrossoverRate: The fraction of the population at the next generation, not including elite children, that is created by the crossover function.\nmutationRate: Probability of chromosome to be mutated\nɛ/epsilon: Positive integer specifies how many individuals in the current generation are guaranteed to survive to the next generation. Floating number specifies fraction of population.\nselection: Selection function\ncrossover: Crossover function (default: identity)\nmutation: Mutation function (default: identity)\n\n\n\n\n\n","category":"type"},{"location":"ga/#Description","page":"Genetic Algorithm","title":"Description","text":"","category":"section"},{"location":"ga/","page":"Genetic Algorithm","title":"Genetic Algorithm","text":"The Genetic Algorithm  is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as Mutation, Crossover and Selection [1].","category":"page"},{"location":"ga/#References","page":"Genetic Algorithm","title":"References","text":"","category":"section"},{"location":"ga/","page":"Genetic Algorithm","title":"Genetic Algorithm","text":"[1]: http://www.scholarpedia.org/article/Genetic_algorithms","category":"page"},{"location":"#Evolutionary.jl","page":"Home","title":"Evolutionary.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package Evolutionary aims to provide a library for evolutionary optimization. It provides implementation of (murho  stackrel+ lambda)-Evolution Strategy, (mumu_I lambda)-Covariance Matrix Adaptation Evolution Strategy, Genetic Algorithm, and Differential Evolution as well as a rich set of mutation, recombination, crossover and selection functions.","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install the package just type","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add Evolutionary","category":"page"},{"location":"","page":"Home","title":"Home","text":"A simple example of using the GA algorithm to find minimum of the Sphere function.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Evolutionary\nresult = Evolutionary.optimize(\n      x -> sum(x.^2), ones(3),\n      GA(populationSize = 100, selection = susinv,\n         crossover = discrete, mutation = domainrange(ones(3))))","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"CurrentModule = Evolutionary","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using Evolutionary","category":"page"},{"location":"tutorial/#Optimization","page":"Tutorial","title":"Optimization","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"To show how the Evolutionary package can be used, we minimize the Rosenbrock function, a classical test problem for numerical optimization. We'll assume that you've already installed the Evolutionary package using Julia's package manager.","category":"page"},{"location":"tutorial/#Objective-Function-Definition","page":"Tutorial","title":"Objective Function Definition","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"First, we load Evolutionary and define the Rosenbrock function:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using Evolutionary\nf(x) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2 # Rosenbrock","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"There are various ways to define your objective function:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For single-objective optimization, the objective function has to have one parameter and return a scalar value, e.g.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"soofun(x) = x[1] + x[2]","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"For multi-objective optimization, the objective function has to return an vector of values, e.g.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"moofun(x) = [ x[1], x[2]+1 ]","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"If multi-objective function has one parameter, the resulting value array will be copied. To reduce, additional data copy, the function can be defined with two parameters to perform in-place change of the result, e.g.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function moofun(F, x)\n    F[1] = x\n    F[2] = x +1\n    F\nend","category":"page"},{"location":"tutorial/#Perform-Optimization","page":"Tutorial","title":"Perform Optimization","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Once we've defined this function, we can find the minimizer (the input that minimizes the objective) and the minimum (the value of the objective at the minimizer) using any of our favorite optimization algorithms. With a function defined, we just specify a form of an individual x of the population for an evolutionary algorithm, and call optimize with a starting individual x0 and a particular optimization algorithm, e.g. CMAES():","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"x0 = [0.0, 0.0];\nEvolutionary.optimize(f, x0, CMAES())","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Evolutionary.optimize","category":"page"},{"location":"tutorial/#Evolutionary.optimize","page":"Tutorial","title":"Evolutionary.optimize","text":"optimize(f[, F], indiv, algo[, opts])\noptimize(f[, F], constr, algo[, opts])\noptimize(f[, F], constr, indiv, algo[, opts])\noptimize(f[, F], constr, algo, poplt[, opts])\n\nPerform optimization of the function f using the alorithm algo with the population, composed of the initial population poplt, or individuals similar to the original individual indiv, or generated from the constraints constr, with the options opts.\n\nFor multi-objective optimization, the objective value F must be provided.\n\n\n\n\n\n","category":"function"},{"location":"tutorial/#Configurable-options","page":"Tutorial","title":"Configurable options","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"There are several options that simply take on some default values if the user doesn't provide any.","category":"page"},{"location":"tutorial/#Algorithm-options","page":"Tutorial","title":"Algorithm options","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"There are different algorithms available in Evolutionary, and they are all listed below. Notice that the constructors are written without input here, but they generally take keywords to tweak the way they work. See the pages describing each solver for more detail.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"GA()\nES()\nCMAES()\nDE()\nNSGA2()\nTreeGP()","category":"page"},{"location":"tutorial/#General-options","page":"Tutorial","title":"General options","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In addition to the algorithm, you can alter the behavior of the optimization procedure by using the following Options keyword arguments:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Options","category":"page"},{"location":"tutorial/#Evolutionary.Options","page":"Tutorial","title":"Evolutionary.Options","text":"There are following options available:\n\nabstol::Float64: the absolute tolerance used in the convergence test (default: 1e-32)\nreltol::Float64: the relative tolerance used in the convergence test (default: 1e-32)\nsuccessive_f_tol::Integer: the additional number of the iterations of the optimization algorithm after the convergence test is satisfied (default: 10)\niterations::Integer: the total number of the iterations of the optimization algorithm (default: 1000)\nshow_trace::Bool: enable the trace information display during the optimization (default: false).\nstore_trace::Bool: enable the trace information capturing during the optimization (default: false). The trace can be accessed by using trace function after optimization is finished.\nshow_every::Integer: show every ns successive trace message (default: 1)\ntime_limit::Float64: the time limit for the optimization run in seconds. If the value set to NaN then the limit is not set. (default: NaN)\ncallback: the callback function that is called after each eteration of the optimization algorithm. The function accepts as parameter a trace dictionary, and must return a boolean value which if true terminates the optimization. (default: nothing)\nparallelization::Symbol: allows parallelization of the population fitness evaluation if set to :thread using multiple threads (default: :serial)\n\n\n\n\n\n","category":"type"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We currently recommend the statically dispatched interface by using the Evolutionary.Options constructor:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"res = Evolutionary.optimize(x->-sum(x),\n                            BitVector(zeros(30)),\n                            GA(selection=uniformranking(5),mutation=flip,crossover=singlepoint),\n                            Evolutionary.Options(iterations=10))","category":"page"},{"location":"tutorial/#Obtaining-results","page":"Tutorial","title":"Obtaining results","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"After we have our results in res object, we can use the API for getting optimization results. This consists of a collection of functions. They are not exported, so they have to be prefixed by Evolutionary.. Say we do the following optimization:","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"res = Evolutionary.optimize(x->-sum(x), BitVector(zeros(3)), GA())","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"You can inspect the result by using a collection of the auxiliary functions, e.g. the minimizer and minimum of the objective functions, which can be found using","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Evolutionary.minimizer(res)\nEvolutionary.minimum(res)","category":"page"},{"location":"tutorial/#Complete-list-of-functions","page":"Tutorial","title":"Complete list of functions","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"An OptimizationResults interface for representing an optimization result.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"OptimizationResults\nsummary(::OptimizationResults)\nminimizer(::OptimizationResults)\nminimum(::OptimizationResults)\niterations(::OptimizationResults)\niteration_limit_reached(::OptimizationResults)\ntrace(::OptimizationResults)\nf_calls(::OptimizationResults)\nabstol(::OptimizationResults)\nreltol(::OptimizationResults)","category":"page"},{"location":"tutorial/#Evolutionary.OptimizationResults","page":"Tutorial","title":"Evolutionary.OptimizationResults","text":"Abstract evolutionary optimization result type\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Base.summary-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Base.summary","text":"summary(result)\n\nShows the optimization algorithm that produced this result.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Evolutionary.minimizer-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Evolutionary.minimizer","text":"minimizer(result)\n\nA minimizer object from the optimization result.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Base.minimum-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Base.minimum","text":"minimum(result)\n\nA minimum value from the optimization result.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Evolutionary.iterations-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Evolutionary.iterations","text":"iterations(result)\n\nA number of iterations to reach the minimum.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Evolutionary.iteration_limit_reached-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Evolutionary.iteration_limit_reached","text":"iteration_limit_reached(result)\n\nReturns true if the iteration limit was reached.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Evolutionary.trace-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Evolutionary.trace","text":"trace(result)\n\nReturns a trace of optimization states from the optimization result.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#NLSolversBase.f_calls-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"NLSolversBase.f_calls","text":"f_calls(result)\n\nReturns a number of an objective function calls.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Evolutionary.abstol-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Evolutionary.abstol","text":"abstol(result)\n\nReturns an absolute tollerance value of the optimization result.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Evolutionary.reltol-Tuple{Evolutionary.OptimizationResults}","page":"Tutorial","title":"Evolutionary.reltol","text":"reltol(result)\n\nReturns a relative tollerance value of the optimization result.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"An implementation of the result object for evolutionary optimizations.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"EvolutionaryOptimizationResults\nconverged(::EvolutionaryOptimizationResults)","category":"page"},{"location":"tutorial/#Evolutionary.EvolutionaryOptimizationResults","page":"Tutorial","title":"Evolutionary.EvolutionaryOptimizationResults","text":"Evolutionary optimization result type\n\n\n\n\n\n","category":"type"},{"location":"tutorial/#Evolutionary.converged-Tuple{Evolutionary.EvolutionaryOptimizationResults}","page":"Tutorial","title":"Evolutionary.converged","text":"converged(result)\n\nReturns true if the optimization sucesfully coverged to a minimum value.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/#Trace","page":"Tutorial","title":"Trace","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"When store_trace and/or show_trace options are set to true in the Options object, an optimization trace is either captured and/or shown on the screen. By default, only the current state minimum value is displayed in the trace. In order to extend trace record, you need to override trace! function providing specialize function behavior on one of specific parameters.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"trace!(::Dict{String,Any}, Any, Any, Any, Any, Any)","category":"page"},{"location":"tutorial/#Evolutionary.trace!-Tuple{Dict{String, Any}, Any, Any, Any, Any, Any}","page":"Tutorial","title":"Evolutionary.trace!","text":"trace!(record::Dict{String,Any}, objfun, state, population, method, options)\n\nUpdate the trace record. This function allows to supplement an additional information into the optimization algorithm trace by modifing a trace record. It can be overwiden by specifing particular parameter types.\n\n\n\n\n\n","category":"method"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Commonly, you would define a specializations of a state, population, or method parameters of trace! function, e.g.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"function trace!(record::Dict{String,Any}, objfun, state, population, method::CMAES, options)\n    record[\"σ\"] = state.σ\nend","category":"page"},{"location":"tutorial/#Parallelization","page":"Tutorial","title":"Parallelization","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"If the objective function is heavily CPU-bound, it's possible to utilize multiple processors/threads to speed up computations. To enable multi-threading evaluation of the objective function, set parallelization option to :thread in the Options object.","category":"page"}]
}
